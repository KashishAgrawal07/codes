{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bac8822-987a-4914-a8e9-fc290aa4830a",
   "metadata": {},
   "source": [
    "Practical No: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8b8b0-e478-479e-9af5-1fc6e753ce0b",
   "metadata": {},
   "source": [
    "Build a Tic-Tac-Toe game using reinforcement learning in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4143612c-022a-44c7-9c98-d00df6a82d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5ce6d5-76e7-4089-9a97-1f5aced59c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define the Tic-Tac-Toe environment and rules\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [' ' for _ in range(9)]\n",
    "        self.current_winner = None\n",
    "\n",
    "    def print_board(self):\n",
    "        for row in [self.board[i*3:(i+1)*3] for i in range(3)]:\n",
    "            print('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "    def available_moves(self):\n",
    "        return [i for i, spot in enumerate(self.board) if spot == ' ']\n",
    "\n",
    "    def empty_squares(self):\n",
    "        return ' ' in self.board\n",
    "\n",
    "    def make_move(self, square, letter):\n",
    "        if self.board[square] == ' ':\n",
    "            self.board[square] = letter\n",
    "            if self.winner(square, letter):\n",
    "                self.current_winner = letter\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def winner(self, square, letter):\n",
    "        # Check row\n",
    "        row_ind = square // 3\n",
    "        row = self.board[row_ind*3:(row_ind+1)*3]\n",
    "        if all([s == letter for s in row]):\n",
    "            return True\n",
    "        # Check column\n",
    "        col_ind = square % 3\n",
    "        col = [self.board[col_ind+i*3] for i in range(3)]\n",
    "        if all([s == letter for s in col]):\n",
    "            return True\n",
    "        # Check diagonals\n",
    "        if square % 2 == 0:\n",
    "            diagonal1 = [self.board[i] for i in [0,4,8]]\n",
    "            diagonal2 = [self.board[i] for i in [2,4,6]]\n",
    "            if all([s == letter for s in diagonal1]) or all([s == letter for s in diagonal2]):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [' ' for _ in range(9)]\n",
    "        self.current_winner = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb4bfff5-1bdf-4d92-8333-dedf865d8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Q-Learning agent for AI\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.3, gamma=0.9, epsilon=0.2):\n",
    "        self.q_table = defaultdict(lambda: np.zeros(9))\n",
    "        self.alpha = alpha    # Learning rate\n",
    "        self.gamma = gamma    # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "\n",
    "    def get_state(self, game):\n",
    "        return ''.join(game.board)\n",
    "\n",
    "    def choose_action(self, game):\n",
    "        state = self.get_state(game)\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(game.available_moves())\n",
    "        else:\n",
    "            q_values = self.q_table[state]\n",
    "            max_q = max([q_values[a] for a in game.available_moves()])\n",
    "            max_actions = [a for a in game.available_moves() if q_values[a] == max_q]\n",
    "            return random.choice(max_actions)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        future = 0 if done else max(self.q_table[next_state])\n",
    "        self.q_table[state][action] += self.alpha * (reward + self.gamma * future - self.q_table[state][action])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b0e040-b821-4467-bcae-81e6ca5c73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train the AI by playing multiple games against random moves\n",
    "def train(agent, episodes=10000):\n",
    "    game = TicTacToe()\n",
    "    for _ in range(episodes):\n",
    "        game.reset()\n",
    "        state = agent.get_state(game)\n",
    "        done = False\n",
    "        while not done:\n",
    "            # AI move\n",
    "            action = agent.choose_action(game)\n",
    "            game.make_move(action, 'X')\n",
    "            next_state = agent.get_state(game)\n",
    "            \n",
    "            if game.current_winner == 'X':\n",
    "                agent.learn(state, action, 1, next_state, True)\n",
    "                done = True\n",
    "            elif not game.empty_squares():\n",
    "                agent.learn(state, action, 0.5, next_state, True)\n",
    "                done = True\n",
    "            else:\n",
    "                # Random opponent move\n",
    "                opponent_action = random.choice(game.available_moves())\n",
    "                game.make_move(opponent_action, 'O')\n",
    "                next_state_op = agent.get_state(game)\n",
    "                if game.current_winner == 'O':\n",
    "                    agent.learn(state, action, -1, next_state_op, True)\n",
    "                    done = True\n",
    "                else:\n",
    "                    agent.learn(state, action, 0, next_state_op, False)\n",
    "                    state = next_state_op\n",
    "\n",
    "# Initialize and train the agent\n",
    "agent = QLearningAgent()\n",
    "train(agent, episodes=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f40ac3-ec4c-4153-962d-5298eb7c3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Play the game interactively with human input\n",
    "def print_board_positions():\n",
    "    print(\"Board positions (0-8):\")\n",
    "    for row in [[str(i+j*3) for i in range(3)] for j in range(3)]:\n",
    "        print('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "def play_human_vs_ai(agent):\n",
    "    game = TicTacToe()\n",
    "    print_board_positions()\n",
    "    game.print_board()\n",
    "    \n",
    "    while game.empty_squares():\n",
    "        # AI move\n",
    "        action = agent.choose_action(game)\n",
    "        game.make_move(action, 'X')\n",
    "        print(\"\\nAI's move:\")\n",
    "        game.print_board()\n",
    "        if game.current_winner == 'X':\n",
    "            print(\"AI wins!\")\n",
    "            return\n",
    "        if not game.empty_squares():\n",
    "            print(\"It's a tie!\")\n",
    "            return\n",
    "\n",
    "        # Human move\n",
    "        valid_move = False\n",
    "        while not valid_move:\n",
    "            try:\n",
    "                human_move = input(\"Enter your move (0-8): \")\n",
    "                if human_move.lower() == 'exit':\n",
    "                    print(\"Game exited.\")\n",
    "                    return\n",
    "                human_move = int(human_move)\n",
    "                if human_move in game.available_moves():\n",
    "                    game.make_move(human_move, 'O')\n",
    "                    valid_move = True\n",
    "                else:\n",
    "                    print(\"Invalid move! Position already taken or out of range.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input! Enter a number between 0 and 8.\")\n",
    "        \n",
    "        print(\"\\nYour move:\")\n",
    "        game.print_board()\n",
    "        if game.current_winner == 'O':\n",
    "            print(\"You win!\")\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876b850b-13ca-4e57-ac25-baeb5a42c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board positions (0-8):\n",
      "| 0 | 1 | 2 |\n",
      "| 3 | 4 | 5 |\n",
      "| 6 | 7 | 8 |\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "\n",
      "AI's move:\n",
      "| X |   |   |\n",
      "|   |   |   |\n",
      "|   |   |   |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your move:\n",
      "| X |   |   |\n",
      "|   | O |   |\n",
      "|   |   |   |\n",
      "\n",
      "AI's move:\n",
      "| X |   |   |\n",
      "| X | O |   |\n",
      "|   |   |   |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your move:\n",
      "| X |   |   |\n",
      "| X | O |   |\n",
      "| O |   |   |\n",
      "\n",
      "AI's move:\n",
      "| X |   | X |\n",
      "| X | O |   |\n",
      "| O |   |   |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your move:\n",
      "| X | O | X |\n",
      "| X | O |   |\n",
      "| O |   |   |\n",
      "\n",
      "AI's move:\n",
      "| X | O | X |\n",
      "| X | O |   |\n",
      "| O | X |   |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your move:\n",
      "| X | O | X |\n",
      "| X | O |   |\n",
      "| O | X | O |\n",
      "\n",
      "AI's move:\n",
      "| X | O | X |\n",
      "| X | O | X |\n",
      "| O | X | O |\n",
      "It's a tie!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Start the interactive game\n",
    "play_human_vs_ai(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7b0cf-e58c-4645-8af5-95a131d7bea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
